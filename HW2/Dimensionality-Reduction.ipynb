{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"abalone\", \"acute-inflammation\", \"acute-nephritis\", \"arrhythmia\", \"bank\", \"breast-cancer\",\n",
    "               \"car\", \"cardiotocography-3clases\", \"congressional-voting\", \"credit-approval\", \"iris\"]\n",
    "path = \"../UA-ECE523-EngrAppMLData/data/\" + datasets[5] + \".csv\"\n",
    "data = np.loadtxt(path, delimiter=\",\")\n",
    "X, y = data[:, :-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X, y, clf):\n",
    "    pca = PCA(n_components=0.90)\n",
    "    pcaX = pca.fit_transform(X)\n",
    "    \n",
    "    score0 = np.mean(cross_val_score(clf, X, y, cv=5))\n",
    "    score1 = np.mean(cross_val_score(clf, pcaX, y, cv=5))\n",
    "    \n",
    "    return score0, score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code tests whether PCA does better than not using a preprocessing technique with a Logistic Regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.64424639 0.54895606]\n",
      " [1.         1.        ]\n",
      " [1.         1.        ]\n",
      " [0.63279761 0.63712768]\n",
      " [0.89493571 0.89117636]\n",
      " [0.70278282 0.68523896]\n",
      " [0.75279944 0.75279944]\n",
      " [0.85137586 0.85797073]\n",
      " [0.6161041  0.62064956]\n",
      " [0.84212625 0.84649554]\n",
      " [0.90666667 0.86666667]]\n",
      "14.0 0.7122984885436232\n",
      "There is not strong evidence to say that using PCA to preprocess the data does better than not using it at the 0.05 level.\n"
     ]
    }
   ],
   "source": [
    "scores = np.zeros((len(datasets), 2))\n",
    "i = 0\n",
    "for dataset in datasets:\n",
    "    path = \"../UA-ECE523-EngrAppMLData/data/\" + dataset + \".csv\"\n",
    "    data = np.loadtxt(path, delimiter=\",\")\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    \n",
    "    scores[i] = score_dataset(X, y, clf)\n",
    "    i += 1\n",
    "\n",
    "print(scores)\n",
    "\n",
    "w, p = wilcoxon(scores[:, 1], scores[:, 0], alternative=\"greater\")\n",
    "print(w, p)\n",
    "if p < 0.1:\n",
    "    print(\"There is strong evidence that using PCA to preprocess the data does better than not using it at the 0.05 level.\")\n",
    "else:\n",
    "    print(\"There is not strong evidence to say that using PCA to preprocess the data does better than not using it at the 0.05 level.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code tests whether PCA does better than not using a preprocessing technique with a Naive Bayes Gaussian classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57052789 0.55591593]\n",
      " [0.82282609 0.94166667]\n",
      " [0.91666667 1.        ]\n",
      " [0.14167139 0.33788957]\n",
      " [0.82504327 0.88608786]\n",
      " [0.67120387 0.66067756]\n",
      " [0.69498252 0.77774566]\n",
      " [0.71309473 0.85422038]\n",
      " [0.55881267 0.57496051]\n",
      " [0.79724011 0.80878173]\n",
      " [0.95333333 0.89333333]]\n",
      "57.0 0.016427109964321847\n",
      "There is strong evidence that using PCA to preprocess the data does better than not using it at the 0.05 level.\n"
     ]
    }
   ],
   "source": [
    "scores = np.zeros((len(datasets), 2))\n",
    "i = 0\n",
    "for dataset in datasets:\n",
    "    path = \"../UA-ECE523-EngrAppMLData/data/\" + dataset + \".csv\"\n",
    "    data = np.loadtxt(path, delimiter=\",\")\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    \n",
    "    scores[i] = score_dataset(X, y, clf)\n",
    "    i += 1\n",
    "\n",
    "print(scores)\n",
    "\n",
    "w, p = wilcoxon(scores[:, 1], scores[:, 0], alternative=\"greater\")\n",
    "print(w, p)\n",
    "if p < 0.1:\n",
    "    print(\"There is strong evidence that using PCA to preprocess the data does better than not using it at the 0.05 level.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
